<html>
<head>
  <meta charset="utf-8" />
  <title>The Most Dangerous Question in AI: "Is it Accurate?"</title>
    <link rel="canonical" href="https://scottlabbe.me/articles/most-dangerous-question/" />
<style>
    body {
      margin: 0 auto;
      width: 744px;
      font-family: Source Serif Pro, serif;
      line-height: 32px;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.7);
      font-size: 21px;
    }
    h1, h2, h3 {
      font-family: Source Sans Pro, Helvetica, Arial, sans-serif;
    }
    h1 a, h1 a:visited {
      color: inherit;
      text-decoration: none;
    }
    h1 {
      line-height: 48px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 42px;
      margin: 32px 0 20px;
    }
    h2 {
      line-height: 32px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 26px;
      margin: 28px 0;
    }
    h3 {
      line-height: 28px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 21px;
      margin: 24px 0;
    }
    p {
      margin: 32px 0;
    }
    .created, .published {
      color: rgba(0, 0, 0, 0.55);
      font-size: 15px;
      line-height: 15px;
      margin: 20px 0;
    }
    .created + .published {
      margin-top: -12px;
    }
    blockquote {
      font-family: Georgia, Source Serif Pro, serif;
      font-style: italic;
      font-size: 24px;
      line-height: 36px;
      margin: 48px 120px;
      text-align: center;
    }
    a {
      word-wrap: break-word;
      outline: none;
      text-decoration: none;
      background-color: transparent;
      border: 0;
      color: #008CC9;
    }
    a:hover {
      text-decoration: underline;
    }
    a:visited {
      color: #8C68CB;
    }
    .center {
      text-align: center;
    }
    iframe {
      display: block;
      margin: 44px auto;
    }
    *:not(pre) + pre, pre:first-of-type {
      margin-top: 32px;
      padding-top: 32px;
    }
    pre:only-of-type {
      margin: 32px 0;
      padding: 32px;
    }
    pre {
      background: #F3F6F8;
      overflow-x: auto;
      display: block;
      font-size: 13px;
      font-family: monospace;
      line-height: 13px;
      padding: 0 32px 32px;
      white-space: pre;
    }
    a.embedded {
      background: #F3F6F8;
      display: block;
      padding: 32px;
      margin: 32px 0;
    }
    img {
      height: auto;
      max-width: 100%;
    }
    .slate-image-embed__resize-full-width img {
      width: 100%;
    }
    .series-logo {
      width: 48px;
      height: 48px;
      box-sizing: border-box;
      background-clip: content-box;
      border: 4px solid transparent;
      border-radius: 6px;
      object-fit: scale-down;
      float: left;
    }
    .series-title {
      font-size: 16px;
      font-weight: 600;
      vertical-align: top;
    }
    .series-description {
      color: rgba(0,0,0,.6);
      font-weight: 400;
      font-size: 14px;
      line-height: 20px;
    }
    div {
      margin: 32px 0;
    }
  </style>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=Space+Mono:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/assets/css/main.css" />
  <style>
    /* Override article styles to match site design */
    body {
      background-color: #FDF5E6;
      color: #333333;
      font-family: 'Libre Baskerville', serif;
      max-width: 800px !important;
      width: 100% !important;
      margin: 0 auto !important;
      padding: 4rem 2rem !important;
      font-size: 1rem;
      line-height: 1.7;
    }
    h1, h2, h3 {
      font-family: 'Space Mono', monospace;
      color: #333333;
      font-weight: 700;
      letter-spacing: -0.5px;
    }
    h1 { font-size: 2rem; margin: 1.5rem 0 0.8rem 0; }
    h2 { font-size: 1.4rem; margin: 1.2rem 0 0.6rem 0; }
    h3 { font-size: 1.1rem; margin: 1rem 0 0.5rem 0; }
    p { margin: 0 0 1rem 0; }
    a { color: #2D5D4B; text-decoration: none; }
    a:hover { text-decoration: underline; }
    ul, ol { margin: 0.9rem 0; padding-left: 1.5rem; }
    li { margin: 0.3rem 0; line-height: 1.7; }
  </style>
  </head>
<body>
    <img src="https://media.licdn.com/mediaD4E12AQE2NYW9vqpeTg" alt="" title="" />
      <h1><a href="https://www.linkedin.com/pulse/most-dangerous-question-ai-accurate-scott-labbe-cpa-7bwve">The Most Dangerous Question in AI: "Is it Accurate?"</a></h1>
    <p class="created">Created on 2025-07-15 12:04</p>
  <p class="published">Published on 2025-07-15 13:40</p>
  <div><p><strong>Why Choosing the Right Metrics Matters More Than Your Model</strong></p><p>I recently trained several fraud-detection systems for a project, and it underlined a critical lesson: <strong>in key processes, what you measure matters more than how you measure it.</strong></p><hr><h3>The Paradox of High Accuracy and Low Utility</h3><p>Consider this: I built a model that was <strong>99.9% accurate but completely useless</strong>. How does that work?</p><p>In the credit-card fraud dataset I used, only 0.1% of transactions were fraudulent. A model that predicts “not fraud” for every transaction would achieve 99.9% accuracy—while catching exactly zero fraud. Technically accurate. Practically worthless.</p><hr><h3>Imbalanced Data and the Limits of Overall Accuracy</h3><p>This exposes the fatal flaw in relying on overall accuracy for imbalanced problems. What we really care about is how well the model flags <strong>fraud</strong>, not simply how often it’s “right” across the board. </p><p>We care about how the model performs on the rare fraudulent cases, not just overall. In machine-learning terms, this is an imbalanced dataset, so selecting appropriate success metrics and accounting for this class imbalance during training should guide model development and evaluation.</p><h3>Precision and Recall: Metrics That Actually Matter</h3><p>For rare-event detection, two metrics become critical. Take the results of the basic logistic regression model for example:</p><h3>Precision: Of all transactions flagged fraud, what percentage are actually fraud?</h3><ul><li><p><strong>Low precision</strong> → fraud analysts drowning in false alarms</p></li><li><p><strong>Example (basic model):</strong> 10.8% (9 false alarms for every real case)</p></li></ul><h3>Recall: Of all actual fraud cases, what percentage do we catch?</h3><ul><li><p><strong>Low recall</strong> → real loss slipping through</p></li><li><p><strong>Example (basic model):</strong> 89.8% (catches most fraud, but at huge cost)</p></li></ul><p>Here's a chart showing the precision-recall curve, in this example, <strong>XGBoost</strong> stays high and to the right for the longest, showing the precision stays high as the recall value increases throughout the chart.</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D4E12AQENcSKU0YQ25Q" src="https://media.licdn.com/dms/image/v2/D4E12AQENcSKU0YQ25Q/article-inline_image-shrink_1500_2232/B4EZgOR2KGHEAU-/0/1752586216414?e=1766620800&amp;v=beta&amp;t=yJnmox7l_OyEOwJnbiJjbKD2za6j48cW7oSpkikB_64"><figcaption>Precision-recall curve showing XGBoost performing best. </figcaption></figure><hr><h3>Connecting Metrics to Business Impact</h3><p>Translating metrics into real-world costs makes the stakes clear:</p><ul><li><p><strong>False positive</strong> → frustrated customers + wasted analyst time</p></li><li><p><strong>False negative</strong> → direct financial loss</p></li></ul><p>To show the business impact of the model choices, we can plot all of the fraud alerts identified by each model and highlight the actual fraud vs. the false alerts. I'm sure the fraud analysis team would be most interested in this chart since the orange bar shows how many fraud alerts they will have to spend analyzing legitimate transactions.</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D4E12AQHsBxelr3GYeA" src="https://media.licdn.com/dms/image/v2/D4E12AQHsBxelr3GYeA/article-inline_image-shrink_1000_1488/B4EZgOSpl3GwAU-/0/1752586427159?e=1766620800&amp;v=beta&amp;t=8MfuhRcNJaZUleWOcABULQRLc0yILct6yWe_-JxRiw0"><figcaption>Chart of fraud alerts applied by each model showing XGBoost identifying the most fraud while minimizing false alerts. </figcaption></figure><hr><h3>Case Study: XGBoost Performance</h3><p>My best model (XGBoost) achieved:</p><ul><li><p><strong>Precision:</strong> 69.7%</p></li><li><p><strong>Recall:</strong> 86.7%</p></li></ul><p><strong>Translation:</strong> fraud analysts spend <strong>6× less</strong> time on false alarms, while still catching <strong>nearly 9 out of 10</strong> fraudulent transactions compared to the basic model.</p><hr><h3>Key Takeaways for Any AI/ML Implementation</h3><ol><li><p><strong>Align metrics with real business costs.</strong></p></li><li><p><strong>Balance competing priorities</strong> (precision vs. recall, speed vs. cost).</p></li><li><p><strong>Translate technical metrics into human impact.</strong></p></li></ol><p>#AI #DataScience #MachineLearning #Analytics #FraudDetection</p></div>
</body>
</html>